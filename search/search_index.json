{
    "docs": [
        {
            "location": "/",
            "text": "LTRDCN-1572\n\n\nWelcome to Cisco Live LTRDCN-1572: VXLAN EVPN Fabric and automation using Ansible.\n\n\nFor full documentation visit \nCisco Live\n.\n\n\nSpeakers\n\n\n\n\nFaisal Chaudhry \nPrincipal Architect, Cisco Advanced Services\n\n\nLei Tian \nSolutions Architect, Cisco Advanced Services",
            "title": "Home"
        },
        {
            "location": "/#ltrdcn-1572",
            "text": "Welcome to Cisco Live LTRDCN-1572: VXLAN EVPN Fabric and automation using Ansible.  For full documentation visit  Cisco Live .",
            "title": "LTRDCN-1572"
        },
        {
            "location": "/#speakers",
            "text": "Faisal Chaudhry  Principal Architect, Cisco Advanced Services  Lei Tian  Solutions Architect, Cisco Advanced Services",
            "title": "Speakers"
        },
        {
            "location": "/intro/",
            "text": "VXLAN\n\n\nVXLAN stands for Virtual Extensible Local Area Network. VXLAN is a L2 overlay scheme on top of L3 network or we can say it is a L2 in layer 3 tunnel. It runs over the existing networks and provides the means to stretch the L2 network. Only VMs within the same VXLAN segment can communicate with each other. Each VXLAN segment is identified by a 24 bit segment ID called \u201cVXLAN Network Identifier (VNI)\u201d.  This help overcome 4094 VLAN scale limitation and able to extend it to 224 segments.\n\n\nVXLAN uses BGP as its control plane for Overlay. It makes it forwarding decisions at VTEPs (Virtual tunnel end points) for layer-2 and layer-3. Forwarding happens based on MAC or IP learnt via control plane (MP-BGP EVPN) . VXLAN uses IGP, PIM and BGP as its underlay in the fabric. \n\n\nBelow are some of the terminologies that will be used in the lab:\n\n\n\n\nVNI / VNID\n \u2013 VXLAN Network Identifier. This replaces VLAN ID \n\n\nVTEP\n \u2013 VXLAN Tunnel End Point.\n\n\nThis is the end point where the box performs VXLAN encap / decap\nThis could be physical HW (Nexus9k) or Virtual (Nexus 1000v, Nexus 9000v)\n\n\n\n\n\n\nVXLAN Segment\n -  The resulting layer 2 overlay network\n\n\nVXLAN Gateway\n \u2013 It is a device that forwards traffic between VXLANS. It can be both L2 and L3 forwarding\n\n\nNVE\n \u2013 Network Virtualization Edge\n\n\nNVE is tunnel interface. It represents VTEP\n\n\n\n\n\n\n\n\nAnsible\n\n\nAnsible is an agentless open source software that can be used for configuration management, deployment and orchestration of deployment. The scripts in Ansible are called playbooks; playbook is in YAML format that was desgiened to be easy for humans to read and write. Playbooks include one or more plays, each play include one or more tasks. Each task is associated with one module, which is what gets executed in the playbook. Modules are python scripts that ship with Ansible installation. During the lab, you will be introduced to multiple NXOS modules and ansible template module. \n\n\nYou can find all Ansible modules documentation at below url:\n\nhttp://docs.ansible.com/ansible/latest/list_of_all_modules.html\n\n\nBelow are some of the terminologies that will be used in the lab:\n\n\n\n\nHost\n: remote machines that Ansible manages  \n\n\nGroup\n: several hosts that can be configured together and share common verables \n\n\nInventory\n: file descripts hosts and groups in Ansible.\n\n\nVariable\n: names of value (int, str, dic, list) referenced in playbook or template\n\n\nYAML\n: data format for Playbook or Variables in Ansible \n\n\nPlaybook\n: the script to orchestrate, automate, deploy system in Ansible. One playbook can include multiple plays. \n\n\nRoles\n: group of tasks, templates to implement specific behavior\n\n\nJinja2\n: a Python based tempting language\n\n\n\n\n\n\nAbout this lab\n\n\nAs a standardized overlay technology, multiple vendors have adopted VXLAN as datacenter solution to provide scalability and allow layer 2 across IP network. MP-BPG EVPN as VXLAN control plane protocol provides a robust scalable solution to overcome the limitation in VXLAN flood and learn mode.\n\n\nAs an open source automation tool, Ansible provides the same framework for network administrators to automate network infrastructure as the rest IT organization. \n\n\nThis lab demostates the possibility of using Ansible to automate datacenter VXLAN fabric day 1 provisiong and day 2 operations. \n\n\nLab Flow\n\n\nLab guide will walk the attendees through the below activities:\n\n\n\n\nAnsible installation \n\n\nAnsible playbook \n\n\nDay 1 automation using Ansible \n\n\nDay 2 automation using Ansible \n\n\nDay 0 automation \n\n\nL4-L7 Service insertion\n\n\n\n\nLab Access\n\n\nBelow table provides the IP addresses and credentials for the devices used in this lab: \n\n\n\n\n\n\n\n\nSpine-1\n\n\n198.18.133.33:1030\n\n\nadmin/C1sco12345\n\n\n\n\n\n\n\n\n\n\nSpine-2\n\n\n198.18.133.33:1040\n\n\nadmin/C1sco12345\n\n\n\n\n\n\nLeaf-1\n\n\n198.18.133.33:1050\n\n\nadmin/C1sco12345\n\n\n\n\n\n\nLeaf-3\n\n\n198.18.133.33:1070\n\n\nadmin/C1sco12345\n\n\n\n\n\n\nLeaf-4\n\n\n198.18.1333.33:1080\n\n\nadmin/C1sco12345\n\n\n\n\n\n\nServer-1\n\n\n198.18.134.50\n\n\nroot/C1sco12345\n\n\n\n\n\n\nServer-3\n\n\n198.18.134.52\n\n\nroot/C1sco12345\n\n\n\n\n\n\nServer-4\n\n\n198.18.134.53\n\n\nroot/C1sco12345\n\n\n\n\n\n\nAnsible Server\n\n\n198.18.134.150\n\n\nroot/C1sco12345\n\n\n\n\n\n\nDCNM\n\n\n198.18.134.200\n\n\nadmin/C1sco12345\n\n\n\n\n\n\nF5\n\n\n198.18.4.10\n\n\nroot/default\n\n\n\n\n\n\nRemote Workstation\n\n\n198.18.133.36\n\n\ndemouser/C1sco12345\n\n\n\n\n\n\n\n\nLab topology\n\n\nBelow picture shows the lab topology:",
            "title": "Introduction"
        },
        {
            "location": "/intro/#vxlan",
            "text": "VXLAN stands for Virtual Extensible Local Area Network. VXLAN is a L2 overlay scheme on top of L3 network or we can say it is a L2 in layer 3 tunnel. It runs over the existing networks and provides the means to stretch the L2 network. Only VMs within the same VXLAN segment can communicate with each other. Each VXLAN segment is identified by a 24 bit segment ID called \u201cVXLAN Network Identifier (VNI)\u201d.  This help overcome 4094 VLAN scale limitation and able to extend it to 224 segments.  VXLAN uses BGP as its control plane for Overlay. It makes it forwarding decisions at VTEPs (Virtual tunnel end points) for layer-2 and layer-3. Forwarding happens based on MAC or IP learnt via control plane (MP-BGP EVPN) . VXLAN uses IGP, PIM and BGP as its underlay in the fabric.   Below are some of the terminologies that will be used in the lab:   VNI / VNID  \u2013 VXLAN Network Identifier. This replaces VLAN ID   VTEP  \u2013 VXLAN Tunnel End Point.  This is the end point where the box performs VXLAN encap / decap\nThis could be physical HW (Nexus9k) or Virtual (Nexus 1000v, Nexus 9000v)    VXLAN Segment  -  The resulting layer 2 overlay network  VXLAN Gateway  \u2013 It is a device that forwards traffic between VXLANS. It can be both L2 and L3 forwarding  NVE  \u2013 Network Virtualization Edge  NVE is tunnel interface. It represents VTEP",
            "title": "VXLAN"
        },
        {
            "location": "/intro/#ansible",
            "text": "Ansible is an agentless open source software that can be used for configuration management, deployment and orchestration of deployment. The scripts in Ansible are called playbooks; playbook is in YAML format that was desgiened to be easy for humans to read and write. Playbooks include one or more plays, each play include one or more tasks. Each task is associated with one module, which is what gets executed in the playbook. Modules are python scripts that ship with Ansible installation. During the lab, you will be introduced to multiple NXOS modules and ansible template module.   You can find all Ansible modules documentation at below url: http://docs.ansible.com/ansible/latest/list_of_all_modules.html  Below are some of the terminologies that will be used in the lab:   Host : remote machines that Ansible manages    Group : several hosts that can be configured together and share common verables   Inventory : file descripts hosts and groups in Ansible.  Variable : names of value (int, str, dic, list) referenced in playbook or template  YAML : data format for Playbook or Variables in Ansible   Playbook : the script to orchestrate, automate, deploy system in Ansible. One playbook can include multiple plays.   Roles : group of tasks, templates to implement specific behavior  Jinja2 : a Python based tempting language",
            "title": "Ansible"
        },
        {
            "location": "/intro/#about-this-lab",
            "text": "As a standardized overlay technology, multiple vendors have adopted VXLAN as datacenter solution to provide scalability and allow layer 2 across IP network. MP-BPG EVPN as VXLAN control plane protocol provides a robust scalable solution to overcome the limitation in VXLAN flood and learn mode.  As an open source automation tool, Ansible provides the same framework for network administrators to automate network infrastructure as the rest IT organization.   This lab demostates the possibility of using Ansible to automate datacenter VXLAN fabric day 1 provisiong and day 2 operations.",
            "title": "About this lab"
        },
        {
            "location": "/intro/#lab-flow",
            "text": "Lab guide will walk the attendees through the below activities:   Ansible installation   Ansible playbook   Day 1 automation using Ansible   Day 2 automation using Ansible   Day 0 automation   L4-L7 Service insertion",
            "title": "Lab Flow"
        },
        {
            "location": "/intro/#lab-access",
            "text": "Below table provides the IP addresses and credentials for the devices used in this lab:      Spine-1  198.18.133.33:1030  admin/C1sco12345      Spine-2  198.18.133.33:1040  admin/C1sco12345    Leaf-1  198.18.133.33:1050  admin/C1sco12345    Leaf-3  198.18.133.33:1070  admin/C1sco12345    Leaf-4  198.18.1333.33:1080  admin/C1sco12345    Server-1  198.18.134.50  root/C1sco12345    Server-3  198.18.134.52  root/C1sco12345    Server-4  198.18.134.53  root/C1sco12345    Ansible Server  198.18.134.150  root/C1sco12345    DCNM  198.18.134.200  admin/C1sco12345    F5  198.18.4.10  root/default    Remote Workstation  198.18.133.36  demouser/C1sco12345",
            "title": "Lab Access"
        },
        {
            "location": "/intro/#lab-topology",
            "text": "Below picture shows the lab topology:",
            "title": "Lab topology"
        },
        {
            "location": "/task1-ansible-node/",
            "text": "Your first task will be to build an Ansible node on a server running redhat CentOS operating system.  At the end of this task, you will have a fully operational Ansible node.\n\n\nStep 1: Connect to lab using anyconnect VPN\n\n\nYou will connect to \ndcloud-lon-anyconnect.cisco.com\n using Cisco VPN AnyConnect client, as shown in below picture, with the username and password provided by the lab admin.\n\n\nNote:\n lab admin will furnish the credentials information to the participant.  If you don't have this information please ask the lab speakers.\n\n\n\n\nStep 2: Enter VPN credentials\n\n\nAfter prompted for credentials, use the credentials provided by the lab admin.    \n\n\u2022   Below is an example of user logging into POD1\n\n\n\n\n\n\nHit accept when the prompt appears to accept the VPN connection login    \n\n\n\n\n\n\nStep 3: RDP to workstation\n\n\nIn this step, you will connect to the workstation with RDP client on your machines.  Use below details for this RDP session:\n\n\n\n\nWorkstation: \n198.18.133.36\n\n\nUsername: \ndcloud\\demouser\n\n\nPassword: \nC1sco12345\n\n\n\n\nBelow screenshot is only an example for this RDP connection:\n\n\n\n\nStep 4: MTputty\n\n\nOnce you have the RDP session to the remote workstation, then you will use MTputty client to connect to all devices in this lab.  \n\n\nMTputty is already installed on the Desktop of the workstation where you connected using RDP.  Run this application by clicking on the icon on the desktop:\n\n\n\n\nStep 5: SSH into Ansible node\n\n\nSSH into Ansible node (198.18.134.150) by double clicking the Ansible icon on the left pan with username \nroot\n and password \nC1sco12345\n\n\n\n\nStep 6: Verify Python\n\n\nOnce successfully SSH into the ansible node, the very first thing we are going to do after logging into Ansible server is verify the python version by running \npython --version\n command - as shown below:\n\n\n[root@rhel7-tools ~]# python --version\nPython 2.7.5\n\n\n\nIt is an important step as we need minimum 2.7.5 version of python in order to install some features for ansbile.  The output of above command confirms this version. \n\n\nAnsible can be run from any machine with Python 2 (versions 2.6 or 2.7) or Python 3 (versions 3.5 and higher) installed. \n\n\n\n\nStep 7: Install PIP\n\n\nAfter verifying we have the minimum version of python installed, we are now going to Install PIP python package using \neasy_install pip\n command as shown below:\n\n\n[root@rhel7-tools ~]# easy_install pip\nSearching for pip\nBest match: pip 8.1.1\nAdding pip 8.1.1 to easy-install.pth file\nInstalling pip script to /usr/bin\nInstalling pip3.5 script to /usr/bin\nInstalling pip3 script to /usr/bin\n\nUsing /usr/lib/python2.7/site-packages\nProcessing dependencies for pip\nFinished processing dependencies for pip\n\n\n\nBelow screenshot shows the execution of above command:\n\n\n\n\nNext, update pip to latest version by executing below command:\n\n\n[root@rhel7-tools ~]# pip install --upgrade pip\n\n\n\nBelow screenshot shows the exection of above command:\n\n\n\n\nAfter installing PIP package, we are going to add the relevant packages that are needed for this Ansible based VXLAN lab. Below are the packages required for this lab.  \n\n\n\n\nParamiko\n\n\nPyYAML\n\n\nJinj2\n\n\nHttplib2\n\n\n\n\nRun below command to install these packages:\n\n\n[root@rhel7-tools ~]# pip install paramiko PyYAML jinja2 httplib2\n\n\n\nBelow screenshot shows the execution of above command:\n\n\n\n\nAs a final step, we are going to install Ansible on this RHEL. Once the install is initiated with the below command, it will take few minutes for it to download and install.\n\n\n[root@rhel7-tools ~]# pip install ansible==2.5.0\n\n\n\nBelow screenshot shows the execution of above command:\n\n\n\n\nStep 8: Verify Ansible\n\n\nAfter installation is complete, check Ansible version by executing the below command:\n\n\n[root@rhel7-tools ~]# ansible --version \nansible 2.5.0\n  config file = None\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/lib/python2.7/site-packages/ansible\n  executable location = /usr/bin/ansible\n  python version = 2.7.5 (default, Apr  9 2015, 11:03:32) [GCC 4.8.3 20140911 (Red Hat 4.8.3-9)]\n[root@rhel7-tools ~]#\n\n\n\nStep 9: Create Ansible Inventory\n\n\nNow, we are going to create inventory, host variables and Configuration file. This is important as Ansible works  against multiple systems in the system by selecting portions of systems listed in Ansible inventory. Similarly, configuration settings in Ansible are adjustable via configuration file.\n\n\nCreate folder named LTRDCN-1572 as working environment and verify that it\u2019s empty:\n\n\n[root@rhel7-tools ~]# mkdir LTRDCN-1572 && cd LTRDCN-1572\n[root@rhel7-tools LTRDCN-1572]# ls\n\n\n\nBelow screenshot shows the execution of above command:\n\n\n\n\nNext:\n\n\n\n\nCreate Ansible inventory file to include Spine and Leaf switches. \n\n\nBy default Ansible has inventory file saved in location /etc/ansible/hosts. \n\n\n\n\nIn this lab we will create hosts file in the working environment. Use \u2018vi\u2019 to create inventory file \u2018hosts\u2019 as shown below:\n\n\n[root@rhel7-tools LTRDCN-1572]# vi hosts\n\n\n\n\n\n\n\nAt the bottom of the inventory file, insert (type i) the following lines:\n\n\n#define global variables, groups and host variables\n[all:vars]\nansible_connection = local\nuser=admin\npwd=C1sco12345\ngather_fact=no\n[jinja2_spine]\n198.18.4.202\n[jinja2_leaf]\n198.18.4.104\n[spine]\n198.18.4.201\n[leaf]\n198.18.4.101\n198.18.4.103\n[server]\n198.18.134.50 eth1=172.21.140.10 gw=172.21.140.1\n198.18.134.52 eth1=172.21.140.11 gw=172.21.140.1\n198.18.134.53 eth1=172.21.141.11 gw=172.21.141.1\n[f5]\n198.18.4.10\n\n\n\n\n\n\n\n\u2022 Quit and save vi editor by press \nEsc\n key and then type \n:wq!\n  \n\n\nBelow screenshot shows the execution of above command:\n\n\n\n\n\n\n\nCreate Ansible config (ansible.cfg) file via vi editor pointing to local \u2018hosts\u2019 file for inventory. Use \nvi ansible.cfg\n to create this file as shown below:\n\n\n[root@rhel7-tools LTRDCN-1572]# vi ansible.cfg\n\n\n\n\n\n\n\nAt the bottom of the ansible.cfg file, insert the following lines (by typing \ni\n):\n\n\n[defaults]\ninventory = hosts\nhost_key_checking = false\nrecord_host_key = true\nstdout_callback = debug\n\n\n\n\n\n\n\nQuit and save \nvi\n editor by press \nEsc\n key and then type \n:wq!\n    \n\n\n\n\n\n\nDo \nls\n to verify the file that you just created under project folder LTRDCN-1572.   \n\n\nBelow screenshot shows the execution of above command:\n\n\n\n\n\n\n\nCreate host variable folder named host_vars in folder LTRDCN-1572. Host varilables can be placed in different places in Ansible. In this lab, we will use host_vars for host variables:\n\n\n[root@rhel7-tools LTRDCN-1572]# mkdir host_vars && cd host_vars\n\n\n\n\n\n\n\nCreate host variable file for each host in inventory. Use \nvi\n to create following file: \n\n\n[root@rhel7-tools host_vars]# vi 198.18.4.101.yml\n\n\n\nIn the file: add below data:\n\n\n---\n  hostname: leaf_1\n  loopback0: 192.168.0.8\n  loopback1: 192.168.0.18\n  router_id: 192.168.0.8\n\n\n\n\n\n\n\nQuit and save \nvi\n editor by press \nEsc\n key and then type \n:wq!\n    \n\n\n\n\n\n\nCreate a new host variable file for next host in inventory. Use \nvi\n to create following file: \n\n\n[root@rhel7-tools host_vars]# vi 198.18.4.201.yml\n\n\n\nIn the file: add below data:\n\n\n---\n  hostname: spine-1\n  loopback0: 192.168.0.6\n  loopback1: 192.168.0.100\n  router_id: 192.168.0.6\n\n\n\n\n\n\n\nQuit and save \nvi\n editor by press \nEsc\n key and then type \n:wq!\n \n\n\n\n\n\n\nCreate a new host variable file for next host in inventory. Use \nvi\n to create following file: \n\n\n[root@rhel7-tools host_vars]# vi 198.18.4.202.yml\n\n\n\nIn the file: add below data:\n\n\n---\n  hostname: spine-2\n  loopback0: 192.168.0.7\n  loopback1: 192.168.0.100\n  router_id: 192.168.0.7\n\n\n\n\n\n\n\nQuit and save \nvi\n editor by press \nEsc\n key and then type \n:wq!\n \n\n\n\n\n\n\nxxxx\n\n\nd",
            "title": "Task 1 - Prepare Ansible node"
        },
        {
            "location": "/task1-ansible-node/#step-1-connect-to-lab-using-anyconnect-vpn",
            "text": "You will connect to  dcloud-lon-anyconnect.cisco.com  using Cisco VPN AnyConnect client, as shown in below picture, with the username and password provided by the lab admin.  Note:  lab admin will furnish the credentials information to the participant.  If you don't have this information please ask the lab speakers.",
            "title": "Step 1: Connect to lab using anyconnect VPN"
        },
        {
            "location": "/task1-ansible-node/#step-2-enter-vpn-credentials",
            "text": "After prompted for credentials, use the credentials provided by the lab admin.     \n\u2022   Below is an example of user logging into POD1    Hit accept when the prompt appears to accept the VPN connection login",
            "title": "Step 2: Enter VPN credentials"
        },
        {
            "location": "/task1-ansible-node/#step-3-rdp-to-workstation",
            "text": "In this step, you will connect to the workstation with RDP client on your machines.  Use below details for this RDP session:   Workstation:  198.18.133.36  Username:  dcloud\\demouser  Password:  C1sco12345   Below screenshot is only an example for this RDP connection:",
            "title": "Step 3: RDP to workstation"
        },
        {
            "location": "/task1-ansible-node/#step-4-mtputty",
            "text": "Once you have the RDP session to the remote workstation, then you will use MTputty client to connect to all devices in this lab.    MTputty is already installed on the Desktop of the workstation where you connected using RDP.  Run this application by clicking on the icon on the desktop:",
            "title": "Step 4: MTputty"
        },
        {
            "location": "/task1-ansible-node/#step-5-ssh-into-ansible-node",
            "text": "SSH into Ansible node (198.18.134.150) by double clicking the Ansible icon on the left pan with username  root  and password  C1sco12345",
            "title": "Step 5: SSH into Ansible node"
        },
        {
            "location": "/task1-ansible-node/#step-6-verify-python",
            "text": "Once successfully SSH into the ansible node, the very first thing we are going to do after logging into Ansible server is verify the python version by running  python --version  command - as shown below:  [root@rhel7-tools ~]# python --version\nPython 2.7.5  It is an important step as we need minimum 2.7.5 version of python in order to install some features for ansbile.  The output of above command confirms this version.   Ansible can be run from any machine with Python 2 (versions 2.6 or 2.7) or Python 3 (versions 3.5 and higher) installed.",
            "title": "Step 6: Verify Python"
        },
        {
            "location": "/task1-ansible-node/#step-7-install-pip",
            "text": "After verifying we have the minimum version of python installed, we are now going to Install PIP python package using  easy_install pip  command as shown below:  [root@rhel7-tools ~]# easy_install pip\nSearching for pip\nBest match: pip 8.1.1\nAdding pip 8.1.1 to easy-install.pth file\nInstalling pip script to /usr/bin\nInstalling pip3.5 script to /usr/bin\nInstalling pip3 script to /usr/bin\n\nUsing /usr/lib/python2.7/site-packages\nProcessing dependencies for pip\nFinished processing dependencies for pip  Below screenshot shows the execution of above command:   Next, update pip to latest version by executing below command:  [root@rhel7-tools ~]# pip install --upgrade pip  Below screenshot shows the exection of above command:   After installing PIP package, we are going to add the relevant packages that are needed for this Ansible based VXLAN lab. Below are the packages required for this lab.     Paramiko  PyYAML  Jinj2  Httplib2   Run below command to install these packages:  [root@rhel7-tools ~]# pip install paramiko PyYAML jinja2 httplib2  Below screenshot shows the execution of above command:   As a final step, we are going to install Ansible on this RHEL. Once the install is initiated with the below command, it will take few minutes for it to download and install.  [root@rhel7-tools ~]# pip install ansible==2.5.0  Below screenshot shows the execution of above command:",
            "title": "Step 7: Install PIP"
        },
        {
            "location": "/task1-ansible-node/#step-8-verify-ansible",
            "text": "After installation is complete, check Ansible version by executing the below command:  [root@rhel7-tools ~]# ansible --version \nansible 2.5.0\n  config file = None\n  configured module search path = [u'/root/.ansible/plugins/modules', u'/usr/share/ansible/plugins/modules']\n  ansible python module location = /usr/lib/python2.7/site-packages/ansible\n  executable location = /usr/bin/ansible\n  python version = 2.7.5 (default, Apr  9 2015, 11:03:32) [GCC 4.8.3 20140911 (Red Hat 4.8.3-9)]\n[root@rhel7-tools ~]#",
            "title": "Step 8: Verify Ansible"
        },
        {
            "location": "/task1-ansible-node/#step-9-create-ansible-inventory",
            "text": "Now, we are going to create inventory, host variables and Configuration file. This is important as Ansible works  against multiple systems in the system by selecting portions of systems listed in Ansible inventory. Similarly, configuration settings in Ansible are adjustable via configuration file.  Create folder named LTRDCN-1572 as working environment and verify that it\u2019s empty:  [root@rhel7-tools ~]# mkdir LTRDCN-1572 && cd LTRDCN-1572\n[root@rhel7-tools LTRDCN-1572]# ls  Below screenshot shows the execution of above command:   Next:   Create Ansible inventory file to include Spine and Leaf switches.   By default Ansible has inventory file saved in location /etc/ansible/hosts.    In this lab we will create hosts file in the working environment. Use \u2018vi\u2019 to create inventory file \u2018hosts\u2019 as shown below:  [root@rhel7-tools LTRDCN-1572]# vi hosts    At the bottom of the inventory file, insert (type i) the following lines:  #define global variables, groups and host variables\n[all:vars]\nansible_connection = local\nuser=admin\npwd=C1sco12345\ngather_fact=no\n[jinja2_spine]\n198.18.4.202\n[jinja2_leaf]\n198.18.4.104\n[spine]\n198.18.4.201\n[leaf]\n198.18.4.101\n198.18.4.103\n[server]\n198.18.134.50 eth1=172.21.140.10 gw=172.21.140.1\n198.18.134.52 eth1=172.21.140.11 gw=172.21.140.1\n198.18.134.53 eth1=172.21.141.11 gw=172.21.141.1\n[f5]\n198.18.4.10    \u2022 Quit and save vi editor by press  Esc  key and then type  :wq!     Below screenshot shows the execution of above command:    Create Ansible config (ansible.cfg) file via vi editor pointing to local \u2018hosts\u2019 file for inventory. Use  vi ansible.cfg  to create this file as shown below:  [root@rhel7-tools LTRDCN-1572]# vi ansible.cfg    At the bottom of the ansible.cfg file, insert the following lines (by typing  i ):  [defaults]\ninventory = hosts\nhost_key_checking = false\nrecord_host_key = true\nstdout_callback = debug    Quit and save  vi  editor by press  Esc  key and then type  :wq!         Do  ls  to verify the file that you just created under project folder LTRDCN-1572.     Below screenshot shows the execution of above command:    Create host variable folder named host_vars in folder LTRDCN-1572. Host varilables can be placed in different places in Ansible. In this lab, we will use host_vars for host variables:  [root@rhel7-tools LTRDCN-1572]# mkdir host_vars && cd host_vars    Create host variable file for each host in inventory. Use  vi  to create following file:   [root@rhel7-tools host_vars]# vi 198.18.4.101.yml  In the file: add below data:  ---\n  hostname: leaf_1\n  loopback0: 192.168.0.8\n  loopback1: 192.168.0.18\n  router_id: 192.168.0.8    Quit and save  vi  editor by press  Esc  key and then type  :wq!         Create a new host variable file for next host in inventory. Use  vi  to create following file:   [root@rhel7-tools host_vars]# vi 198.18.4.201.yml  In the file: add below data:  ---\n  hostname: spine-1\n  loopback0: 192.168.0.6\n  loopback1: 192.168.0.100\n  router_id: 192.168.0.6    Quit and save  vi  editor by press  Esc  key and then type  :wq!      Create a new host variable file for next host in inventory. Use  vi  to create following file:   [root@rhel7-tools host_vars]# vi 198.18.4.202.yml  In the file: add below data:  ---\n  hostname: spine-2\n  loopback0: 192.168.0.7\n  loopback1: 192.168.0.100\n  router_id: 192.168.0.7    Quit and save  vi  editor by press  Esc  key and then type  :wq!      xxxx  d",
            "title": "Step 9: Create Ansible Inventory"
        }
    ]
}